# iKUN：无需重新训练即可与跟踪器对话

## 第1章：背景知识

### 1.1. 多目标跟踪（Multi-Object Tracking, MOT）

多目标跟踪是计算机视觉中的一项基础任务，旨在在视频序列中同时检测并跟踪多个目标对象。典型的做法是 **检测-跟踪** 范式：先在每一帧中检测出所有目标的位置，然后通过关联算法将不同帧中的相同目标匹配起来，形成连续的轨迹。MOT 通常聚焦于预定义类别的目标，例如行人或车辆，并要求在每帧中标注这些目标并保持其身份的一致性。MOT 在视频监控、自动驾驶等领域有广泛应用，不过传统 MOT 模型在目标类别和场景上缺乏灵活的泛化能力。

### 1.2. 基于语言描述的多目标跟踪（Referring Multi-Object Tracking, RMOT）

为提升跟踪的灵活性，近期提出了 **基于语言描述的多目标跟踪（RMOT）**。RMOT 的核心思想是利用自然语言来指引跟踪过程：即给定一段文字描述，让跟踪器仅输出满足该描述的目标轨迹。例如，输入查询描述“左侧移动的汽车”，那么跟踪器应当在视频中找到所有 **符合该描述** 的汽车，并返回它们的运动轨迹。

相比传统 MOT 需要预先指定目标类别，RMOT 允许用户用任意描述（颜色、位置、状态等）来定位目标，极大提高了灵活性。然而，这种灵活性也带来了挑战：模型需要 **同时** 执行检测、关联和语言匹配三项子任务。这意味着 RMOT 模型在训练时要在同一框架下 **平衡多种任务的优化**，不但增加了训练难度，也容易出现不同任务间的 **竞争**，导致性能下降。

### 1.3. 长尾分布与开放集测试

由于描述语言的多样性，RMOT 任务中常出现 **长尾分布** 现象：少数描述（例如常见颜色或简单描述）有大量正样本，而许多细节丰富或不常见的描述仅对应极少的样本。与传统长尾问题不同的是，RMOT 在 **测试集** 中也呈现非均匀的长尾分布——某些描述在测试集中出现频率很低。这意味着如果模型仅在训练时针对长尾分布调整，那么在测试时仍可能面临罕见描述带来的不确定性。

此外，RMOT 还是一个 **开放集** 任务，表示测试时可能出现训练集中从未见过的全新描述。模型必须能够处理这些 **未见描述**，这超出了传统封闭集假设（测试描述与训练分布相同）的范围。长尾分布和开放集的存在，对 RMOT 模型的 **泛化能力** 和 **鲁棒性** 提出了更高要求，需要特殊的策略来应对。

### 1.4. 常用多目标跟踪算法概述

在深入 iKUN 之前，有必要了解几种经典的多目标跟踪器，它们往往作为“现成的”（off-the-shelf）基线可与 iKUN 结合使用：

- **SORT**：一种简单高效的跟踪器，使用卡尔曼滤波进行运动预测，并通过边界框的重叠（IoU）来关联目标。SORT 强调快速跟踪，但在外观差异大的场景中关联效果有限。
- **DeepSORT**：在 SORT 的基础上加入了卷积神经网络提取的 **外观特征**。在进行关联时，DeepSORT 不仅考虑运动的相近程度（例如预测位置与检测位置的差距），还考虑目标的外观向量的距离。通过增加外观信息，DeepSORT 显著降低了身份切换错误，使跟踪更稳定。
- **ByteTrack**：该方法提出了“关联每一个检测框”的策略。具体而言，ByteTrack 在关联过程中将高置信度和低置信度的检测结果都纳入考虑，而不是像传统方法那样直接丢弃低置信度检测。这样可以 **恢复漏检目标** 的轨迹，从而提升跟踪召回率。
- **OC-SORT**：一种改进的跟踪方法，全称为 **高斯分布中心轨迹排序**（Orthogonal Center SORT）。OC-SORT 在 SORT 的基础上进行了多项改进，例如利用目标的 **瞬时速度** 辅助关联，以及在目标脱出画面时及时终止轨迹等。这些改进有助于降低误关联和身份切换，使跟踪更可靠。OC-SORT 等方法代表了通过更智能的关联和后处理策略改进 MOT 性能的思路。

以上跟踪器大多遵循 **跟踪-by-检测** 框架，并且 **普遍使用卡尔曼滤波** 进行目标状态预测。它们的区别主要在于：是否使用深度特征、如何处理低置信度检测，以及关联策略和轨迹管理的不同。

### 1.5. 卡尔曼滤波简介

**卡尔曼滤波（Kalman Filter）** 是 MOT 中常用的运动建模方法。它是一种递归估计算法，可在离散时间序列上对物体的运动状态（如位置、速度）进行预测和更新。具体而言，卡尔曼滤波在每一帧包含两个阶段：

1. **预测**：根据上一时刻的状态和预设的运动模型，预测当前时刻物体的状态分布。这一步会考虑模型的不确定性，通常假设一个过程噪声协方差矩阵 $Q$ 来描述运动模型误差。
2. **更新**：一旦获得当前帧的观测（例如检测到的目标位置），将观测与预测进行融合。融合时依赖 **卡尔曼增益**，其计算取决于预测的不确定性和测量的不确定性。测量不确定性通常由测量噪声协方差矩阵 $R$ 描述。通过融合，得到当前时刻更加精确的状态估计和新的不确定性估计。

在 MOT 跟踪器中，卡尔曼滤波常用于预测目标在下一帧的大概位置，从而缩小需要寻找对应检测的范围。它的效果高度依赖于参数设置，例如过程噪声 $Q$ 和观测噪声 $R$。传统跟踪器中，这些参数通常是 **手工设定** 的固定值，需要根据场景调优。如果参数设定不当，卡尔曼滤波可能 **无法适应运动状态的变化**，导致预测不准或者更新偏差。

iKUN 提出的 **神经卡尔曼滤波** 正是为了解决此问题，通过学习自适应调整 $Q$ 和 $R$ 提升跟踪性能，我们将在后续章节详述。

### 1.6. CLIP 模型简介

**CLIP（Contrastive Language-Image Pre-Training）** 是 OpenAI 提出的一种跨模态模型，能够将图像和文本映射到同一特征空间。CLIP 由一个图像编码器和一个文本编码器构成，两者在训练时通过对比学习相互配合：给定配对的图文数据，训练使得对应的图像向量和文本向量在特征空间中距离接近，不匹配的则距离远。经过在 4 亿对图文数据上的大规模预训练，CLIP 学会了广泛的视觉概念和其文本描述之间的对齐关系。

这意味着，使用 CLIP 提取图像和文本特征，可以直接计算两者的相似度来判断这段文本是否可能描述该图像，具备 **零样本识别** 能力。对于 RMOT 任务，CLIP 看起来是一个理想的基础模块：我们可以用它的图像编码器来获得目标的视觉特征，用文本编码器处理查询描述，然后比较相似度以决定该目标是否匹配描述。

CLIP 的优点在于 **视觉-语言对齐** 效果好，覆盖面广，不需要为新概念专门训练。但需要注意的是，CLIP 的图像和文本编码过程是 **独立** 的：对于给定图像，CLIP 总是输出相同的视觉特征（与输入文本无关）。而在 RMOT 中，一个轨迹往往对应多种不同描述（颜色、位置、行为等）。让一个固定的图像特征同时匹配多样的文本描述是困难的。iKUN 为此设计了新的模块来克服 CLIP 这方面的局限，这将在 **第2章** 详细介绍。

------

## 第2章：iKUN 核心组件

iKUN（insertable **Knowledge Unification Network**）是一个可插入的子网络，它在不改动原有跟踪器的情况下，为多目标跟踪器赋予“听懂”文本指令的能力。

iKUN 包含三个核心组成部分：

- **知识统一模块（KUM）**
- **神经卡尔曼滤波器（NKF）**
- **相似度校准方法**

下面将分别介绍各部分的设计思想和工作原理。

### 2.1. 知识统一模块（KUM）及其三种变体

**知识统一模块（Knowledge Unification Module, KUM）** 旨在融合视觉和文本信息，从而自适应地提取与查询描述相关的目标特征。传统做法（例如直接使用 CLIP）是**独立**提取视觉特征和文本特征，然后计算相似度。但是正如前述，CLIP 那样的独立编码会产生“一对多匹配”的难题：一个轨迹（视觉特征）可能需要对应多种不同文本描述。KUM 的思路是在提取视觉特征时 **引入文本指导**，让视觉编码器针对当前的文本描述 **调整关注的重点**，从而为每种描述提取出不同的视觉特征表示。这类似于在人类描述同一对象的不同属性时，我们的注意力会侧重于对象的不同方面——比如描述颜色时注重颜色区域，描述动作时注重运动轨迹。通过 KUM，模型可以针对描述中的关键信息提炼视觉特征，使得后续的匹配更加准确。

![image-20250411124723750](https://raw.githubusercontent.com/YuuJW/Typora_images/main/img/image-20250411124723750.png?token=A42E44TJNJSNVHXOSUG6ZQ3H7CPRM)

论文中探讨了 KUM 的三种不同设计方案（变体）。它们都遵循上述 **“文本引导视觉”** 的基本思想，但在融合方式上有所区别：

------

1. **级联注意力（Cascade Attention）**：
    首先，将目标的 **局部特征** $f_{local}$（例如目标在各帧中的外观特征）和 **全局特征** $f_{global}$（例如整个场景或邻域的特征）通过交叉注意力融合在一起。在这一步，$f_{local}$ 作为查询（query），$f_{global}$ 作为键值（key/value），通过交叉注意力获取结合了局部和上下文的信息。
    融合结果再与文本特征 $f_t$ 进行第二次交叉注意力融合，并采用残差乘法的方式叠加文本影响。简而言之，文本特征在第二步充当了指导作用，细调视觉特征提取过程。这种两阶段 **先视觉后文本** 的级联注意力机制，使得最终输出的统一特征既包含视觉的细节和上下文，又突出与描述相关的部分。

------

1. **互相关（Cross Correlation）**：
    同样地，先融合局部特征 $f_{local}$ 与全局特征 $f_{global}$。随后，设计一个 **描述条件的动态卷积** 操作。具体而言，根据文本特征 $f_t$ 生成一组动态卷积核（kernel），并将其应用在融合后的视觉特征上，执行跨模态的互相关运算。
    这个过程可以理解为：文本内容决定“关注模板”，该模板在视觉特征图上滑动以提取与描述模式匹配的部分。互相关机制常用于相关滤波跟踪器中，这里借鉴来实现 **文本引导下的模式匹配**。相比级联注意力，该方法以卷积形式融合，具有明确的空间匹配含义。

------

1. **文本优先调制（Text-first Modulation）**：
    与前两种先融合视觉、后作用文本不同，此设计将文本特征引入得 **更早**。具体来说，先用文本特征 $f_t$ 对局部特征 $f_{local}$ 和全局特征 $f_{global}$ 分别进行调制（例如通过通道加权或门控等方式，让文本影响这两个视觉特征的表示），然后再将经过调制的两种视觉特征进行交叉注意力融合。如此，文本从一开始就指导视觉特征提取的过程，确保最终融合时，两种视觉特征已经带有文本所关心的信息。**文本优先** 策略突出语言在线索提取阶段的作用。

------

这三种变体分别侧重不同的融合顺序和机制：“级联注意力”和“互相关”首先强化视觉特征之间的结合，再引入文本；“文本优先调制”则是文本信息预先参与每个视觉分支的提取。实验结果表明，这些设计都明显优于不使用文本指导的基线方法，证明了引入文本引导对于特征统一的重要性。在实际实现中，iKUN 采用了其中一种默认的 KUM 设计（论文默认用“级联注意力”作为 KUM 的实现），后文将基于该默认设计进行讲解。

### 2.2. 神经卡尔曼滤波器（NKF）

**神经卡尔曼滤波器（Neural Kalman Filter, NKF）** 是 iKUN 针对跟踪任务引入的一个改进模块，用于动态调整卡尔曼滤波的噪声参数。正如 **第1章** 所述，标准卡尔曼滤波中的过程噪声协方差 $Q$（建模运动的不确定性）和观测噪声协方差 $R$（建模检测误差）通常是固定预设的。但在实际视频中，不同目标、不同运动状态下，这两个值的最优设定可能相差甚远。

例如，**高速运动**的物体需要更大的过程噪声以涵盖位置预测的不确定性，而**缓慢平稳**运动的物体则应降低过程噪声以避免过度发散。同理，**高可信度**的检测（例如清晰目标）对应较小的观测噪声，而**低质量**检测（模糊、遮挡）则需要增大观测噪声以降低信任度。固定的 $Q$ 和 $R$ 无法适应这种变化，可能导致预测阶段过于自信或更新阶段过于相信有噪声的观测，从而降低跟踪精度。

NKF 的核心是在卡尔曼滤波每个时间步，利用 **神经网络** 根据当前的运动状态估计出合适的 $Q_k$ 和 $R_k$。具体做法是构建两个子网络：$F_Q$（Q-Net）和 $F_R$（R-Net）。在第 $k$ 帧：

- **Q-Net**：$F_Q(x_{k-1})$ 接收先前时刻的状态估计 $x_{k-1}$（通常包含目标速度信息）作为输入，输出一个新的过程噪声 $Q_k$。这意味着根据目标之前的运动状况（例如速度快慢、方向变化等），来调整预测阶段对不确定性的估计。
- **R-Net**：$F_R(z_k)$ 则利用当前帧的观测 $z_k$（例如检测框坐标、检测置信度等）来输出一个新的观测噪声 $R_k$。也就是根据当前观测质量，动态确定更新阶段应赋予观测多大信任。

通过这两个网络，卡尔曼滤波的预测和更新步骤将变得 **自适应**：当目标运动剧烈时，$F_Q$ 会让预测更保守（增大 $Q$）；当目标运动平稳时，则减小 $Q$ 以获取更精确预测。同样，$F_R$ 会在观测可靠时减小 $R$ 强化更新，在观测可疑时增大 $R$ 保持滤波稳定。

值得注意的是，为了保持轻量，作者发现使用简单的全连接网络就足以胜任该任务；更复杂的时序网络（如 LSTM、GRU）并未带来明显增益。这可能是因为卡尔曼滤波自身已经在时间上递归，而决定 $Q$ 和 $R$ 的因素更多取决于当前即时的状态与观测。

在实现上，iKUN 将 NKF 集成到经典跟踪器中形成了新的跟踪器 **NeuralSORT**。NeuralSORT 以 DeepSORT 为基础，引入了 NKF 以替代原固定参数的卡尔曼滤波，并结合了一些 OC-SORT 的后处理技巧（如利用速度辅助关联、越界退出等）。实验表明，NKF 能够有效提高跟踪精度和稳健性：在 KITTI 和 DanceTrack 等数据集上，加入 NKF 的 NeuralSORT 相比原有跟踪器在多项指标上都有明显提升。

这证明了 **学习型滤波** 相较于 **手工调参滤波** 的优势——模型可以根据环境自动校准参数，适应更复杂多变的场景。

------

### 2.3. 相似度校准方法

**相似度校准（Similarity Calibration）** 是 iKUN 在测试阶段采用的一种策略，用于应对 **长尾分布** 和 **开放集** 描述带来的不利影响。其基本想法是在模型计算出轨迹与文本描述的相似度分数后，对该分数进行一次基于描述流行度的调整，从而 **重新校准模型对该分数的置信度**。

为何需要校准？前文提到，描述的长尾分布意味着模型在训练时对某些常见描述可能见过大量样本，而对冷门描述样本极少甚至没有见过（开放集）。**未经处理的模型可能对频繁出现的描述过于自信，而对稀有描述信心不足**，或者相反，根据训练分布产生偏差。这会导致在测试时，一些本应匹配的目标因为描述不常见而得分偏低被错判，或者反之亦然。

相似度校准方法通过 **伪频率（pseudo frequency）** 来调整分数。具体步骤包括：

- **估计描述的伪频率**：在不直接知道测试描述真实频率的情况下，iKUN 利用 **预训练的 CLIP 文本编码器** 对描述进行嵌入。然后，将该嵌入与训练集中所有描述的嵌入进行比较，以估计这条描述在训练语料中的“相似出现频率”。简单来说，如果一个测试描述与多条常见训练描述在语义上相近，可以认为它的伪频率较高；反之，如果它语义上很独特，与训练描述相差甚远，则视为伪频率低。这个过程给予了开放集描述一个参考的“常见程度”度量。
- **映射函数调整分数**：根据估计出的伪频率值，利用一个预先设定的映射函数 $f(\cdot)$ 对模型输出的相似度进行缩放或平移调整。例如，伪频率低的描述，其相关轨迹分数可能适当放大以避免漏检；伪频率高的描述，分数则可略微缩小以防止过度自信。

论文中采用了一个形如 $f(x) = a \cdot x + b$ 的线性或近线性函数来对分数进行变换，并通过验证集调整了参数 $a$ 和 $b$（默认取 $a = 8, b = -0.1$）。这种调整幅度并不剧烈，但足以平衡由于描述罕见程度不同导致的评分偏差。据报道，使用相似度校准可使 HOTA 评价指标再提升约 0.8%。

重要的是，相似度校准 **只在测试推理阶段** 应用，训练过程中并未引入这一机制。这保证了模型学习到的是 **原始匹配能力**，而校准仅仅作为推理时的一层后处理来提高鲁棒性。

通过相似度校准，iKUN 可以更有效地处理 **未见过或罕见的描述**，降低长尾效应带来的不利影响，从而在各种文本查询下均能保持较可靠的表现。

## 第3章：问题陈述与创新点

本章我们总结iKUN试图解决的问题，以及它所提出的具体创新。

### 3.1. 现有方法面临的问题

以往的RMOT方法（例如TransRMOT）通常采用**端到端联合模型**：将一个语言模块直接嵌入现有多目标跟踪器中，使模型从图像到文本匹配一步训练完成 。这种“一体化”的框架存在多方面局限：

- **任务竞争**：联合模型需要同时优化**检测、关联、语言指引**三项任务。各任务的目标不尽相同，共享的模型参数会在梯度更新中相互制约。例如，检测希望更稳健地识别物体位置，关联强调时序匹配的连续性，而语言匹配关注语义特征，这些目标可能在模型学习时彼此拉扯。已有研究指出，即使只联合检测和关联（传统MOT），二者的优化就存在冲突。加入语言后，任务竞争更加严重 ，可能导致各子任务都无法达到最优性能。
- **工程代价**：在联合框架下，语言模块深度耦合在跟踪器内部。如果想**更换底层跟踪算法**（例如从DeepSORT换成ByteTrack），往往需要对整个模型代码进行改动并重新训练全模型。这使得研究者无法方便地复用最新最强的跟踪器成果，限制了灵活性和拓展性。每次更换跟踪器的代价很高，不利于快速实验迭代。
- **训练成本**：端到端训练一个同时执行检测、跟踪、匹配的模型对**计算资源**要求极高。需要大量的数据和时间来协调不同模块参数的学习。训练过程中各部分容易出现**不平衡**（例如检测损失远大于语言损失），需要精心调参。总体而言，这类模型训练调试复杂、耗时长。
- **固定运动模型局限**：传统跟踪器内部采用固定参数的卡尔曼滤波，无法适应多变的运动模式。在复杂场景下，速度变化和观测质量变化会导致跟踪不准，但原有模型无法动态调整，限制了跟踪精度。
- **长尾描述泛化欠佳**：早期方法通常**忽略了描述分布的不均衡**。如果训练数据对某类描述偏好，模型在测试时容易对罕见描述表现不佳。同时，**未见过的新描述**也难以处理，因为模型没有相应的先验去判断这些描述的可靠性和匹配阈值。

### 3.2. iKUN的创新解决方案

针对上述痛点，iKUN提出了一系列新思路，将RMOT任务拆解开来并引入专门模块，提高性能的同时保持了极高的灵活性：

![image-20250411125425571](https://raw.githubusercontent.com/YuuJW/Typora_images/main/img/image-20250411125425571.png?token=A42E44XPAXW2BMIDO5VH7UTH7CQL2)

- **跟踪与指引解耦**：iKUN采用“**先跟踪，后指引**”的两阶段框架 。首先利用现成的MOT算法跟踪出视频中所有可能目标（无论类别如何），然后在这些轨迹上应用语言模块进行筛选。这种解耦意味着**基础跟踪器**和**语言匹配器**是独立的模块：训练时将**跟踪器冻结不动**，仅训练iKUN模块来理解语言和识别目标 。通过将检测、关联任务从训练目标中移除，优化过程能**专注于语言指引子任务**。这避免了多任务竞争，大大简化了训练难度。同时，由于跟踪器权重不变，任何已训练好的iKUN模块都可以无缝衔接不同的跟踪器，实现**一次训练，多处使用**。工程上，研究者可以自由切换更先进的检测器或关联算法，而无需推倒重来训练整个模型。
- **知识统一模块（KUM）**：为解决“**一轨迹对应多描述**”的问题，iKUN引入了KUM来**动态调整视觉特征**。KUM通过与文本特征的交互，针对给定描述提取出与之**匹配度最高**的目标特征表示。例如，面对同一个目标轨迹，输入描述如果强调颜色，KUM就会引导视觉编码器更多关注目标的颜色特征；描述若强调动作，KUM则让编码器突出运动模式信息。这样，原本固定的视觉特征被**文本“调制”\**成了\**描述相关**的特征，更易于后续判别。本质上，KUM通过**跨模态注意力融合**和**动态卷积**等机制，实现了视觉与语言知识的统一建模，使模型具备**按需提取**不同视觉信息的能力。在实验中，无论采用哪种具体变体的KUM，都明显提升了匹配准确率。
- **神经卡尔曼滤波（NKF）**：iKUN针对跟踪器的运动模型提出了NKF模块，让滤波参数从**静态**走向**自适应**。NKF通过R-Net和Q-Net实时感知运动状态和检测质量，调整卡尔曼滤波的增益计算 。这种做法消除了手工调节噪声参数的需要，使跟踪器能根据场景自动优化跟踪效果。例如，在拥挤场景或剧烈运动时，NKF会相应增大不确定性，防止丢失目标；在平稳简单情况下，又会缩小不确定性以精确跟踪。实验结果展示了NKF对各类基线跟踪算法的通用提升。这项创新解决了以往滤波器参数不鲁棒的问题，使跟踪部分更加可靠，为后续的语言匹配提供了高质量的轨迹输入。
- **相似度校准**：面对长尾分布和未见描述，iKUN没有止步于训练时的数据采样调整，而是增加了推理阶段的相似度校准**后处理**。通过引入**伪频率**这一中间量，iKUN能够**识别出哪些描述在训练中相对罕见**，并相应地**修正匹配分数**。这一创新思路等价于在模型之外再加一道“经验校正”，避免模型因为训练偏见而过度自信或过度犹豫。特别是在模型从未见过的描述上，校准提供了一种**开放集适应**机制，使模型的输出更稳健一致。这样的设计在此前的RMOT方法中是没有的，属于iKUN对长尾开放场景的特有贡献。

总的来说，iKUN通过**模块化设计**和**训练/推理策略创新**，成功地解决了传统RMOT方法中的诸多难点。其可插拔框架不仅性能卓越，还方便结合各种现有技术，加速了该领域的研究和应用进程。此外，作者还构建了新的**Refer-Dance**数据集，将DanceTrack扩展加入描述，进一步推动了RMOT的研究（数据集不属本文重点，这里不展开）。

## 第4章：训练策略

### 4.1. iKUN 的训练流程

iKUN 采用 **分步训练** 策略，区别于传统端到端方法。训练过程主要分为两部分：**iKUN 语言匹配模块的训练**，以及 **NKF 子模块的训练**（后者针对跟踪器部分）。

1. **冻结跟踪器，训练 iKUN 模块**：训练 iKUN 时，使用的是提前准备好的轨迹数据，而非实时的检测结果。具体来说，利用带有文字描述标签的视频数据集（如 Refer-KITTI），通过标注直接获得每个视频中所有目标的真实轨迹（即 GT 轨迹）。这些轨迹看作“完美跟踪器”的输出，每条轨迹配有一个或多个文本描述。训练时，将这些 GT 轨迹送入视觉编码分支，对应描述输入文本编码分支，模型输出轨迹与描述的相似度评分。匹配的轨迹-描述对设为正样本，其他设为负样本，构造监督信号。
2. **损失函数与优化**：针对匹配任务，iKUN 使用 **焦点损失（Focal Loss）** 进行训练。焦点损失适用于处理正负样本极度不平衡的问题（正样本远少于负样本），可降低大量简单负样本的权重，聚焦于难分样本。训练目标是让匹配轨迹输出高相似度（标签为1），不相关轨迹输出低相似度（标签为0）。通过最小化焦点损失，模型持续优化视觉编码、KUM 及匹配模块。
3. **冻结文本编码器**：iKUN 使用 CLIP 的文本编码器，并在训练时保持其冻结。这样做可减轻训练负担，避免小数据集导致的语义漂移。视觉编码器部分（如 ResNet）根据需要微调；KUM 和匹配模块从随机初始化开始训练。
4. **训练配置**：论文中在 Refer-KITTI 上训练了 100 个 epoch，初始学习率为 $1e{-5}$（采用余弦退火策略）。整个训练过程**不涉及跟踪器的参数更新**，即检测器与关联算法保持原状。最终训练出的 iKUN 模块是一个独立的语言过滤器，能够接受任意多目标轨迹并输出匹配得分。
5. **NKF 的训练**：NKF 模块训练的是 Q-Net 和 R-Net 两个子网络。该任务本质上是一个回归问题，目标是预测最优的 $Q$ 和 $R$。训练方式是用带标注的视频运行基线跟踪器，计算预测与真实位置的偏差，并用 **均方误差（MSE）损失** 反向优化参数。训练轮数较少（如论文中为 10 个 epoch）。训练好的 NKF 可直接接入任何跟踪器，无需微调。

------

### 4.2. 与传统联合模型的比较

iKUN 的训练策略与传统 RMOT 联合训练模型的主要区别如下：

- **解耦训练 vs 联合训练**：传统模型将检测、关联、语言模块联合优化，而 iKUN 解耦了这些任务，仅训练语言模块，跟踪器权重冻结。这样避免了多任务竞争，训练更稳定，尤其适用于小数据集。
- **一次训练，多模型通用**：iKUN 模块训练后即可接入不同跟踪器使用，无需针对每个跟踪器重复训练。相比之下，联合模型更换底层检测器或结构后需整体重训，代价较高。
- **利用理想轨迹训练**：iKUN 直接用 GT 轨迹训练语言模块，相当于在最理想输入下学习“匹配上限能力”。而联合模型训练初期轨迹质量较差，语言模块学习受到干扰。
- **训练成本更低**：iKUN 训练的网络规模小、无需全盘反向传播，因此训练时间短、资源需求低。相比之下，联合模型包含复杂结构（检测、语言编码等），训练负担更重。

------

总之，iKUN 采用一种“牺牲端到端、换取稳定与泛化”的训练思路，在实践中证明效果良好。冻结跟踪器而只训练匹配模块，既避免了多任务耦合的复杂性，又大幅度提升了系统的适配灵活性与工程复用价值。

## 第5章：推理过程与损失机制

本章我们将完整梳理iKUN在推理（推断）阶段的工作流程，从输入视频和文本描述一直到输出最终的匹配轨迹结果，并解释其中涉及的相似度计算和在训练时使用的损失函数机制。

### 推理流程分步解析

当用户输入一段 **视频 + 自然语言描述** 后，iKUN 将执行以下步骤，输出对应的目标轨迹。

------

#### 1. 输入准备

用户提供一段视频序列以及一条自然语言描述（如“穿红衣服跳舞的人”），可能涉及目标的颜色、动作、位置等属性。系统首先对视频进行帧级预处理（如尺寸归一化），此部分与常规视觉任务一致。

------

#### 2. 多目标检测与跟踪

视频帧送入一个预设的 **多目标跟踪器**（如 YOLOv8 + DeepSORT）：

- 检测器在每帧中识别出所有目标并给出边界框和置信度；
- 跟踪器利用卡尔曼滤波、匈牙利算法或 ByteTrack 将检测结果在时间上关联为轨迹。

输出为一组轨迹，每条轨迹由若干检测框组成，并带有唯一 ID。此阶段不涉及任何语言信息，目标是覆盖视频中**所有可追踪对象**，以避免漏检潜在匹配目标。

------

#### 3. 轨迹特征提取（视觉流）

对每条轨迹，iKUN 提取两类特征：

- **局部特征 $f_{local}$**：裁剪目标框图像，通过 CNN（如 ResNet）提取多帧外观特征后融合（如平均或 LSTM）。
- **全局特征 $f_{global}$**：提取目标所在帧的上下文区域或整图特征，反映目标所处环境。

这两类特征将被送入 **知识统一模块（KUM）** 与文本特征联合建模。

------

#### 4. 文本特征提取（文本流）

iKUN 使用冻结的 **CLIP 文本编码器** 将自然语言描述编码为语义向量 $f_t$，其与视觉特征同维度。由于 CLIP 的通用性，即使描述包含训练集未出现的词汇（如“紫色长裙”），也能较好地完成语义表示。

------

#### 5. 知识融合（KUM）

当视觉特征 $(f_{local}, f_{global})$ 与文本特征 $f_t$ 准备好后，送入 KUM：

1. 通过交叉注意力将 $f_{global}$ 融合进 $f_{local}$；
2. 然后将 $f_t$ 调制该融合结果，强化与描述相关的视觉维度。

输出为融合后的统一特征 $f_{uni}$，该特征已根据文本语义动态调整，可更好地区分不同描述下的视觉信息。注意：每条轨迹单独处理，不存在干扰。

------

#### 6. 时间建模

若轨迹包含多帧，iKUN 将对所有时间步的 $f_{uni}$ 特征执行时间聚合：

- 默认使用 **平均池化**，即计算每帧融合特征的均值，得到最终视觉特征 $f_v$；
- 若目标动作剧烈或外观变化大，亦可采用加权聚合或 RNN（论文中称平均池化已足够）。

------

#### 7. 相似度计算

使用 **余弦相似度** 计算轨迹视觉特征 $f_v$ 与文本特征 $f_t$ 的匹配度：
$$
\text{sim}(f_v, f_t) = \frac{f_v \cdot f_t}{\|f_v\| \cdot \|f_t\|}
$$
该分数反映了轨迹与描述语义的贴合程度，数值越高表示匹配越好。此余弦匹配正是训练时的监督信号来源。

------

#### 8. 相似度校准与筛选决策

iKUN 对所有轨迹的相似度分数执行后处理：

- **相似度校准（可选）**：若启用，将根据描述的“伪频率”对分数做线性调整，避免模型对冷门描述置信不足（见第 2 章）。
- **目标筛选策略**：
  - 设定阈值，筛除分数较低轨迹；
  - 若描述为单数形式（如“the person”），可取分数最高者；
  - 若描述为复数（如“所有小孩”），可保留所有超阈值轨迹。

阈值可在验证集调优，以兼顾准确率与召回率。

------

#### 9. 输出格式

最终输出为符合描述的轨迹集合，每条包含：

- 所在帧编号；
- 对应边界框（位置坐标）；
- 可选信息：轨迹 ID、匹配得分等。

------

> ✅ **灵活性强调**：iKUN 在整个过程中作为一个**语言过滤后处理模块**，不需更改原始跟踪器结构。任何能提供轨迹输出的跟踪器皆可与 iKUN 搭配使用，体现出极高的兼容性与扩展性。

#### 损失函数与训练信号

在训练阶段，iKUN 主要优化语言匹配准确性与滤波器稳定性，采用以下损失机制：

##### 匹配损失（语言子任务）

- iKUN 使用 **焦点损失（Focal Loss）** 来训练轨迹-描述的匹配任务，将每对轨迹与描述视为一个训练样本，正负样本按是否匹配标注为 1 或 0。

- 模型输出为余弦相似度，映射到 $[0,1]$ 区间后，与标签共同计算焦点损失：
  $$
  \mathrm{FL}(p, y) = -\alpha (1 - p)^\gamma y \log(p) - (1 - \alpha) p^\gamma (1 - y) \log(1 - p)
  $$
  其中 $p$ 是预测概率，$y$ 是标签，$\alpha$ 与 $\gamma$ 控制负样本抑制程度。

- 焦点损失能有效抑制大量易判别负样本的影响，强调困难样本学习。相比普通交叉熵，在匹配数据中正负样本极度不平衡的情况下更稳定，避免模型陷入“恒输出负”的局部最优。

##### NKF 回归损失

- NKF 中的 Q-Net 与 R-Net 使用 **均方误差（MSE）损失**，训练其预测的过程噪声 $Q_k$ 和观测噪声 $R_k$ 接近“理想参数”。
- 理想参数可通过真实轨迹离线回代估算，或根据追踪误差最小化构造目标函数。
- MSE 损失促使两个子网络学会根据状态输入与观测质量，自适应调整滤波器增益，提升预测精度与鲁棒性。由于 NKF 的功能是增强基础追踪，因此它与语言匹配任务训练上相对独立，可先独立训练完成再集成。

##### 模块分离优化

- iKUN 的训练是**模块化的**：先在 GT 轨迹上训练语言匹配模块，再在追踪输出上训练 NKF。避免了直接设计一个大规模联合损失，降低训练复杂度与不稳定性。
- 虽然训练时模块各自优化，但在推理阶段它们可以无缝协作：先追踪，再匹配；模块之间数据流自然衔接，无需再联合微调。

##### 推理阶段逻辑

- 推理时系统不会再涉及任何损失计算。所有参数都已经冻结，执行的是一系列 **无梯度的前向推理步骤**。
- iKUN 只需执行一次特征编码 + 相似度匹配 + 分数判断 + 可选校准，即可完成从“描述”到“目标”的精准映射。

------

综上，iKUN 借助清晰分离的训练逻辑、精设计的损失函数与高效模块化协作，在保持推理高效的同时，实现了对复杂语言目标的精准筛选。即使不改动底层跟踪器，也能让系统具备“理解语言、筛选目标”的 RMOT 能力，真正做到 **开箱即用、性能稳健**。